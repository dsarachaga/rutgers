---
title: "Homework 7"
author: "Diego Saráchaga"
date: "March 27, 2019"
output:
  html_document: default
  pdf_document: default
---


```{r setup, include=FALSE}

library(tidyverse)
library(rvest)
library(lubridate)
library(stringr)
library(httr)
library(curl)
library(jsonlite)
library(kableExtra)
library(printr)
library(tidytext)
library(wordcloud)
library(dplyr)

source("api-keys.R")

```
### Exercise 2   


-----

Look at the API documentation at https://dev.socrata.com/foundry/healthdata.nj.gov/9hse-wixk.   



#### Part a) 
##### _Question:_   

Write a function that will use the API and then generate a plot of the rate of heart disease over time by year. Set the default to all races, but include an option to specify the race. To get ggplot2 to generate a plot from within a function, wrap the nal object in the print() function. Be sure to include in your RMarkdown a plot generated by your
function, using the default of all races and another using one specific race.   

----
##### _Answer:_   


First, I get the table from the url, and take a look at its structure.

```{r prelim_2a, error = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
url <- "https://healthdata.nj.gov/resource/5dpz-3wxj.json"
  
json_result <- url %>% curl() %>% readLines()

# prettify(json_result) #This line is commented because I would make the report too large
  
heart_disease <- json_result %>% fromJSON() %>% as.data.frame()
head(heart_disease)
  
```   
-----   

Now, I implement the function, first by cleaning the data set, and then by filtering only the rows I need for the plot. In the function, as it was specified, __\"All\"__ is the default selection if nothing is passed through.   
Finally, I plot the result and also use _print()_ for the final object.   


```{r part_2a1, error = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
heart_disease_by_year <-function(race_selected = "All")
{
  url <- "https://healthdata.nj.gov/resource/5dpz-3wxj.json"
  
  json_result <- url %>% curl() %>% readLines()
  
  heart_disease <- json_result %>% fromJSON() %>% as.data.frame()
  
  heart_disease.clean <- heart_disease %>% 
    mutate(heartdisease = as.numeric(heartdisease)) %>%
    mutate(year = as.numeric(year))
  
  heart_disease.plot <- heart_disease.clean  %>%
    subset(!is.na(heartdisease)) %>%
    filter(race == race_selected)
  
  min_plot <- min(heart_disease.plot$heartdisease)
  max_plot <- max(heart_disease.plot$heartdisease)
  
  heart_disease.plot <- heart_disease.clean  %>%
    subset(!is.na(heartdisease)) %>%
    filter(year != "Target") %>%
    filter(race == race_selected)
  
  heart_disease.target <- heart_disease  %>%
    subset(!is.na(heartdisease)) %>%
    filter(year == "Target") %>%
    filter(race == race_selected)
  
  heart_disease.target <- heart_disease.target$heartdisease %>% as.numeric()
  
  print(heart_disease.plot)  
  
  ggplot(heart_disease.plot, aes(year, heartdisease)) + 
    geom_point() + 
    geom_smooth() +
    ylim(min_plot, max_plot) +
    ggtitle(paste("Heart Disease vs Year. Race selection:", race_selected)) +
    geom_hline(yintercept = heart_disease.target, color = "red") +
    xlab("Year") +
    ylab("Heart Disease")

}

```


----    


When the function is ready, I called it for some races to show how it works


-----   


```{r part_2a2, error = TRUE, message = FALSE, warning = FALSE, eval = TRUE}

heart_disease_by_year()
heart_disease_by_year("Hispanic")

```

-----   


### Exercise 3   


-----

The __New York Times__ has a nice set of APIs, described at https://developer.nytimes.com/apis.    

----   

#### Part b) 
##### _Question:_   

Make 2 barplots, one with the most common non-stop-words in the titles of the Most Popular articles by views for the past week (https://developer.nytimes.com/docs/most-popular-product/1/overview) and another of the most common non-stop-words in the titles of the "world" Top Stories articles (https://developer.nytimes.com/docs/top-stories-product/1/overview).

----    

##### _Answer:_     


First, I got myself an API key to do the exercise. Then, I searched for the url that I needed to call the APIs.  
After that, for each of the JSONs obtained, first I looked for the correct variable name to get the titles.   
Next, I **anti_join** them with the stop words, and count how many of the remaining words where in all of the titles. In this step, I added a filter to keep out the words that were actually numbers.    
Finally, I did a bar plot of the most common non-stop-words in the titles for each of the API calls.    

---- 

First, for *Most Popular articles*:  


```{r part_3bMostPop, error = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
url.MostPopular <- paste0(
    "https://api.nytimes.com/svc/mostpopular/v2/viewed/1.json?api-key=", 
    api.key.NYTimesMostPop
  )

json_result.MostPopular <- url.MostPopular %>% curl() %>% readLines()

# prettify(json_result.MostPopular) #This line is commented because I would make the report too large

MostPopular.titles <-json_result.MostPopular %>% fromJSON() %>% 
  .$results %>% .$title 

MostPopular.stop_words <-
  tibble(title = MostPopular.titles) %>%
  unnest_tokens(word, title) %>%
  anti_join(stop_words) %>%
  count(word, sort = TRUE) %>%
  filter(!grepl("\\d+\\.*\\d*", word)) %>%
  arrange(desc(n)) %>%
  head(10)

ggplot(MostPopular.stop_words, aes(word, n)) +
  ggtitle("Top 10 Most common non-stop words in the titles of the Most Popular articles") + 
  xlab("Word in title") +
  ylab("Count") +
  geom_bar(stat="identity", fill = "dodgerblue4") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))
````   

----   

Then, for *World Top Stories*:  


```{r part_3bWorldTop, error = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
url.WorldTop <- paste0(
  "https://api.nytimes.com/svc/topstories/v2/world.json?api-key=", 
  api.key.NYTimesTopStories
)

json_result.WorldTop <- 
  url.WorldTop %>% fromJSON()

names(json_result.WorldTop)
names(json_result.WorldTop$results)

WorldTop.titles <- json_result.WorldTop %>% .$results %>% .$title 

WorldTop.stop_words <-
  tibble(title = WorldTop.titles) %>%
  unnest_tokens(word, title) %>%
  anti_join(stop_words) %>%
  filter(!grepl("\\d+\\.*\\d*", word)) %>%  #I add this filter so I keep only words and not numbers
  count(word, sort = TRUE) %>%
  arrange(desc(n)) %>%
  head(10)

ggplot(WorldTop.stop_words, aes(word, n)) +
  geom_bar(stat="identity", fill = "dodgerblue4") +
  ggtitle("Top 10 Most common non-stop words in the titles of the World Top Stories articles") + 
  xlab("Word in title") +
  ylab("Count") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))

````   

-----   


### Exercise 4   


-----

Taking advantage of the rvest package, turn the table at http://www.nature.com/articles/ng.3097/tables/3 into an R data frame.   

----   


First, I got the data set from the url.   


```{r prelim_4, error = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
url_genetics <- "http://www.nature.com/articles/ng.3097/tables/3"

nature_genetics <- url_genetics %>%
  read_html() %>% 
  html_table(fill = TRUE) %>% 
  as.data.frame()

head(nature_genetics)
```

-----    


#### Part a) 
##### _Question:_   

Be sure to delete the rows "Genes with previous literature support (GRAIL)" and "New genes without previous evidence" (and don't do it by using the row number).

----    

##### _Answer:_     

Checking the table, the rows that contain "Genes with previous literature support (GRAIL)" and "New genes without previous evidence" are always the same, so I can erase them by just searching for them in one of the variables.


```{r part_4a, error = TRUE, message = FALSE, warning = FALSE, eval = TRUE}

nature_genetics.clean <- nature_genetics %>%
  subset(!(str_trim(Locus..height.SNP.) %in% 
             c("Genes with previous literature support (GRAIL)","New genes without previous evidence")))

head(nature_genetics.clean)

```


-----    


#### Part b) 
##### _Question:_   

Be sure to convert the p-value column to numbers.

----    

##### _Answer:_     

First, I separate the value from the exponential part of the p-value into two columns.    
Then, the **'-'** was not the one used for numeric values, so I changed it.    
Finally, I put the two columns together into a new one *p-value*, that will be the one showing the numeric values.   


```{r part_4b, error = TRUE, message = FALSE, warning = FALSE, eval = TRUE}

nature_genetics.clean <- 
  nature_genetics.clean %>% separate(Prioritization.P.value, c("p_value", "exponential"), sep = " × 10")

nature_genetics.clean$exponential <- nature_genetics.clean$exponential %>%
  str_replace_all("−", "-")

nature_genetics.clean <- nature_genetics.clean %>% 
  mutate(p_value = as.numeric(paste0(p_value,'e',replace_na(exponential,1))))
  
nature_genetics.clean <- subset(nature_genetics.clean, select=-c(exponential))

nature_genetics.clean$p_value
```



-----    


#### Part c) 
##### _Question:_   

The last column is shown in 3 rows in the journal, but most likely as one string in your table. Use regular expressions to insert semicolons (i.e., \;") between each of the original lines. For example, "PI3K cascade (REACTOME, P = 6.2 x 10-13); Chronic myeloid leukemia (KEGG, P= 1.6 x 10-12); Response to broblast growth factor stimulus (GO, P = 5.4 x 10-11)"

----    

##### _Answer:_     

For this part, I realize that the **';'** should be after each **'('**, so I used a *str_replace_all*, adding each **'('** a **';'** after it.   

```{r part_4c, error = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
nature_genetics.clean$Top.ranking.reconstituted.gene.sets <- 
  nature_genetics.clean$Top.ranking.reconstituted.gene.sets %>% str_replace_all("\\) ", "\\); ") %>%
  str_trim()

head(nature_genetics.clean$Top.ranking.reconstituted.gene.sets)

```



-----    


#### Part d) 
##### _Question:_   

Show the table in your RMarkdown le by using the function knitr::kable().

----    

##### _Answer:_     

For this part, I realize that the **';'** should be after each **'('**, so I used a *str_replace_all*, adding each **'('** a **';'** after it.   

```{r part_4d, error = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
nature_genetics.clean %>%
  kable(digits = 20, col.names = c("Locus (height SNP)",
                                   "Gene",
                                   "New locus",
                                   "Prioritization P value",
                                   "Lines of supporting evidence",
                                   "Top-ranking reconstituted gene sets")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))
```